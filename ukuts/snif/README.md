# Сборщик ID из ФГИС "Аршин"

Автоматизированный инструмент для массового сбора идентификаторов записей о поверке средств измерений из Федеральной государственной информационной системы обеспечения единства измерений (ФГИС "Аршин").

## Описание

Скрипт выполняет автоматический поиск и сбор идентификаторов (`vri_id`) из базы данных ФГИС "Аршин" по списку поисковых запросов. Поддерживает фильтрацию по году поверки, автоматическую пагинацию, обработку ошибок с повторными попытками и возможность продолжения работы после прерывания.

### Основные возможности

- **Массовая обработка запросов** из CSV-файла
- **Автоматическая пагинация** для получения всех результатов
- **Умные задержки** между запросами для избежания блокировок
- **Retry-механизм** с экспоненциальным backoff при ошибках
- **Сохранение прогресса** — можно прервать и продолжить позже
- **Управление cookies** для имитации браузерной сессии
- **Экспорт результатов** в JSON и CSV форматах

## Требования

- **Node.js** версии 18 или выше (18+, 20+, 22+)
- **npm** для установки зависимостей

## Установка

1. Клонируйте или скачайте проект
2. Установите зависимости:

```bash
npm install
```

Будут установлены:
- `axios` — HTTP-клиент для запросов
- `tough-cookie` — управление cookies
- `axios-cookiejar-support` — интеграция cookies с axios
- `playwright` (dev) — опционально для тестирования

## Использование

### Подготовка входных данных

Создайте CSV-файл с запросами (по умолчанию `queries.csv`):

```csv
query,year
10300309,2025
229450,2025
774951,2025
1342А/1342,2025
201026625,2025
201025665,
5706А/5706,2025
```

**Формат:**
- **query** (обязательно) — поисковый запрос (номер СИ, название, модель и т.д.)
- **year** (опционально) — год поверки для фильтрации (можно оставить пустым)

### Запуск

Базовый запуск с параметрами по умолчанию:

```bash
node fetch-arshin-ids.mjs
```

Запуск с настройками:

```bash
node fetch-arshin-ids.mjs --csv=queries.csv --rows=50 --minDelay=3000 --maxDelay=9000 --timeout=60000
```

### Параметры командной строки

| Параметр | Значение по умолчанию | Описание |
|----------|----------------------|----------|
| `--csv` | `queries.csv` | Путь к входному CSV-файлу с запросами |
| `--rows` | `50` | Количество записей на одну страницу результатов |
| `--minDelay` | `3000` | Минимальная задержка между запросами (мс) |
| `--maxDelay` | `9000` | Максимальная задержка между запросами (мс) |
| `--timeout` | `60000` | Таймаут HTTP-запроса (мс) |
| `--retries` | `5` | Максимальное количество повторных попыток при ошибке |
| `--maxPages` | `0` | Лимит страниц на запрос (0 = без лимита) |

### Примеры использования

**Быстрый сбор с короткими задержками:**
```bash
node fetch-arshin-ids.mjs --minDelay=1000 --maxDelay=3000
```

**Осторожный режим с длинными паузами:**
```bash
node fetch-arshin-ids.mjs --minDelay=5000 --maxDelay=15000
```

**Ограничение по страницам (для тестирования):**
```bash
node fetch-arshin-ids.mjs --maxPages=3
```

**Собственный CSV-файл:**
```bash
node fetch-arshin-ids.mjs --csv=my-queries.csv
```

## Выходные файлы

После выполнения скрипт создаёт три файла:

### 1. `ids.json`
Подробные результаты в JSON-формате:

```json
[
  {
    "query": "10300309",
    "year": "2025",
    "ids": ["123456789", "987654321"],
    "found": 2,
    "pages": 1,
    "numFound": 2
  }
]
```

**Поля:**
- `query` — исходный поисковый запрос
- `year` — год фильтрации
- `ids` — массив найденных vri_id
- `found` — количество уникальных ID
- `pages` — количество обработанных страниц
- `numFound` — общее количество результатов по API

### 2. `ids.csv`
Плоский список результатов в CSV:

```csv
query,year,vri_id
"10300309","2025","123456789"
"10300309","2025","987654321"
"229450","2025","111222333"
```

Удобен для импорта в Excel, базы данных или дальнейшей обработки.

### 3. `progress.json`
Файл прогресса для возобновления работы:

```json
{
  "index": 3,
  "results": [...]
}
```

**Назначение:** если скрипт прервётся (ошибка, Ctrl+C), при следующем запуске он продолжит с места остановки.

## Как это работает

### Архитектура

```
┌─────────────┐
│ queries.csv │
└──────┬──────┘
       │
       ▼
┌─────────────────────────────────┐
│  fetch-arshin-ids.mjs           │
│  ┌───────────────────────────┐  │
│  │ 1. Загрузка CSV           │  │
│  │ 2. Восстановление прогресса│  │
│  │ 3. Создание HTTP-клиента  │  │
│  │ 4. Цикл по запросам       │  │
│  │    ├─ Пагинация           │  │
│  │    ├─ Сбор vri_id         │  │
│  │    ├─ Задержки            │  │
│  │    └─ Сохранение прогресса│  │
│  └───────────────────────────┘  │
└─────────────┬───────────────────┘
              │
              ▼
┌──────────────────────────────────┐
│ ids.json + ids.csv + progress.json│
└──────────────────────────────────┘
```

### Процесс работы

1. **Инициализация**
   - Парсинг CSV с запросами
   - Загрузка сохранённого прогресса (если есть)
   - Создание HTTP-клиента с cookie jar

2. **Прогрев сессии**
   - Запрос к странице результатов для получения session cookie
   - Имитация поведения браузера

3. **Обработка запросов**
   - Для каждого запроса из CSV:
     - Формирование параметров поиска
     - Пагинация по всем страницам результатов
     - Извлечение уникальных `vri_id`
     - Случайная задержка между запросами

4. **Обработка ошибок**
   - При HTTP 403/405/429 — экспоненциальный backoff
   - При сетевых ошибках — повторные попытки
   - Максимум 5 попыток на запрос

5. **Сохранение результатов**
   - После каждого запроса обновляется `progress.json`
   - В конце создаются финальные `ids.json` и `ids.csv`

### API эндпоинт

Скрипт обращается к:
```
https://fgis.gost.ru/fundmetrology/cm/xcdb/vri/select
```

**Параметры запроса:**
- `fq` — фильтр запроса (query + year)
- `q` — основной запрос (всегда `*`)
- `fl` — список полей для возврата
- `sort` — сортировка результатов
- `rows` — количество записей на страницу
- `start` — смещение для пагинации

## Особенности реализации

### Управление cookies
Скрипт использует `tough-cookie` для хранения cookies между запросами, что позволяет поддерживать сессию как в браузере.

### Случайные задержки
Задержки между запросами рандомизированы в диапазоне `minDelay`-`maxDelay` для имитации человеческого поведения и снижения риска блокировки.

### Retry-механизм
При ошибках применяется экспоненциальный backoff:
- Попытка 1: ~2-4 сек
- Попытка 2: ~4-8 сек
- Попытка 3: ~8-16 сек
- И т.д. до максимума 60 сек

### Возобновление работы
Файл `progress.json` позволяет продолжить сбор после прерывания. Уже обработанные запросы пропускаются.

## Устранение проблем

### Ошибка "В CSV нет столбца query"
Убедитесь, что первая строка CSV содержит заголовок `query,year`.

### HTTP 403/405/429 ошибки
Сервер блокирует запросы. Решения:
- Увеличьте задержки: `--minDelay=10000 --maxDelay=20000`
- Уменьшите `--rows` до 20-30
- Запускайте в нерабочее время

### Таймауты
Увеличьте таймаут: `--timeout=120000` (2 минуты)

### Неполные результаты
Проверьте `progress.json` — возможно, скрипт прервался. Просто запустите снова.

### Удаление прогресса
Чтобы начать сначала, удалите `progress.json`:
```bash
rm progress.json
```

## Рекомендации

1. **Начните с малого** — протестируйте на 2-3 запросах
2. **Используйте разумные задержки** — 3-9 секунд обычно достаточно
3. **Запускайте в фоне** для больших списков:
   ```bash
   nohup node fetch-arshin-ids.mjs > output.log 2>&1 &
   ```
4. **Сохраняйте резервные копии** `progress.json` при длительных сборах
5. **Не злоупотребляйте** — уважайте ресурсы сервера

## Лицензия

Проект предоставляется "как есть" для образовательных и исследовательских целей.

## Поддержка

При возникновении проблем проверьте:
- Версию Node.js: `node --version` (должна быть 18+)
- Доступность сайта: https://fgis.gost.ru/fundmetrology/cm/results
- Логи выполнения скрипта

---

**Примечание:** Скрипт предназначен для легального сбора публичных данных. Соблюдайте правила использования ФГИС "Аршин" и не создавайте чрезмерную нагрузку на сервер.
